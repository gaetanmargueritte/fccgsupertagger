# Callable file reading a discourse provided in french via input file
# outputs a file with the same discourse supertagged with CCG
# Tags are generated by a trained model which is either trained or to-be-trained

import pickle
import sys
import os
import argparse
import time
import torch
from model import Tagger
from dataHandle import fetch_and_format_data

device = "cuda" if torch.cuda.is_available() else "cpu"



if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="French CCG supertagger [main].")
    parser.add_argument(
        "-m",
        "--model",
        default="",
        type=str,
        help="Trained model weights dictionary file",
    )
    parser.add_argument(
        "-d",
        "--data",
        default="",
        type=str,
        help="Trained model data file (.pickle file)",
    )
    parser.add_argument(
        "-i",
        "--input",
        default="",
        type=str,
        help="Discourse formulated in French natural language.",
    )
    parser.add_argument(
        "-o",
        "--output",
        default="tagged_discourse.txt",
        type=str,
        help="tagged discourse file (default: tagged_discourse.txt",
    )
    parser.add_argument(
        "--max-sequence-length",
        default=120,
        type=int,
        help="Max sequence length (default: 120)",
    )
    parameters = parser.parse_args()
    model_file: str = parameters.model
    data_file: str = parameters.data
    input_file: str = parameters.input
    output_file: str = parameters.output
    max_sequence_length: int = parameters.max_sequence_length

    if not os.path.exists(model_file) or not os.path.isfile(model_file):
        print(
            "Model weights dictionary file invalid. It can be generated by calling the file train.py."
        )
        print("Exiting program.")
        sys.exit(1)
    if not os.path.exists(data_file) or not os.path.isfile(data_file):
        print(
            "Model data file invalid. It can be generated by calling the file train.py."
        )
        print("Exiting program.")
        sys.exit(1)
    if not os.path.exists(input_file) or not os.path.isfile(input_file):
        print("Input file invalid.")
        print("Exiting program.")
        sys.exit(1)

    start = time.time()
    print("**** Model loading... ****")
    with open(data_file, "rb") as f:
        model_data = pickle.load(f)
    model = Tagger(
        None,
        model_data["lemma_embed_size"],
        model_data["postag_embed_size"],
        model_data["deprel_embed_size"],
        model_data["nb_output_class"],
        model_data["ccgs2id"],
        model_data["vocab_size"],
        hidden_size=model_data["hidden_size"],
        max_sequence_length=model_data["max_sequence_length"],
    )
    model.load_state_dict(torch.load(model_file))
    model.to(device)
    print("**** Done. ****")

    with torch.no_grad():
        print("**** Starting data preprocessing... ****")
        (
            batch_text,
            batch_words,
            batch_lemmas,
            batch_postags,
            batch_deprels,
            batch_masks,
        ) = fetch_and_format_data(input_file, model_data, max_sequence_length)
        print("**** Done. ****")
        predictions = model(
            batch_words.to(device), batch_lemmas.to(device), batch_postags.to(device), batch_deprels.to(device), batch_masks.to(device)
        )
        end = time.time()
        print(f"Predicted {len(batch_text)} sentences in {end-start}s.")
        id2ccgs = model_data["id2ccgs"]
        for i in range(len(batch_text)):
            for t, p in zip(batch_text[i].split(), predictions[i]):
                print(f"{t} - {id2ccgs[p]}")
            print("------------")
